My paper list.

[Hallucination](file:///C:/Users/91338/AppData/Local/Temp/MarkdownPadPreview.html#Hallucination),
[Classics](file:///C:/Users/91338/AppData/Local/Temp/MarkdownPadPreview.html#Classical),
[Instruction Tuning](file:///C:/Users/91338/AppData/Local/Temp/MarkdownPadPreview.html#Instruction_Tuning),
[Multi-task Learning](file:///C:/Users/91338/AppData/Local/Temp/MarkdownPadPreview.html#MTL),


## Some paper list
 - [https://github.com/DengBoCong/nlp-paper?tab=readme-ov-file](https://github.com/DengBoCong/nlp-paper?tab=readme-ov-file)
 - [https://scholar.google.com/citations?user=E0iCaa4AAAAJ&hl=en&oi=sra](https://scholar.google.com/citations?user=E0iCaa4AAAAJ&hl=en&oi=sra)
 - [https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:natural_language_processing](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label:natural_language_processing)


## <a id="Hallucination">Hallucination</a>
 - **Cognitive Mirage: A Review of Hallucinations in Large Language Models**. Hongbin Ye et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Cognitive_Mirage_A_Review_of_Hallucinations_in_Large_Language_Models.pdf))([link](http://arxiv.org/abs/2309.06794v1)).
   - Taxonomy of Hallucination
     - Question and Answer
     - Dialog system
     - Summarization system
     - Knowledge Graph with LLMs
     - Cross-model system
   - Detection
     - Classifier
     - Uncertainty Metric: 1)ASTSN: logit output values in their prediction response. 2)BARTSCORE 3)KoK 4)SLAG 5)KLD 6) POLAR
     - Self-Evaluation
     - Evidence Retrieval
 - **A Survey of Hallucination in Large Foundation Models**. Vipula Rawte et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\A_Survey_of_Hallucination_in_Large_Foundation_Models.pdf))([link](http://arxiv.org/abs/2309.05922v1)).
   - Dataset:Med-HALT (Medical Domain Hallucination Test)
 - **Med-HALT: Medical Domain Hallucination Test for Large Language Models**. Ankit Pal et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Med-HALT_Medical_Domain_Hallucination_Test_for_Large_Language_Models.pdf))([link](http://arxiv.org/abs/2307.15343v2)).
   - [https://medhalt.github.io/](https://medhalt.github.io/)
   - Baseline Models: GPT-3.5 Turbo, Falcon(Penedoetal.,2023b), MPT(MosaicML,2023) and Llama-2(Touvronetal.,2023).
   - Evaluation matrices: Accuracy, **PointwiseScore**

## <a id="Classical">Classical</a>
 - **A unified architecture for natural language processing**. Collobert Ronan et.al. **No journal**, **2008**, **Number of Citations: **2448, ([pdf](.\Papers\A_unified_architecture_for_natural_language_processing.pdf))([link](http://dx.doi.org/10.1145/1390156.1390177)).
 - **Imagenet classification with deep convolutional neural networks**. A Krizhevsky et.al. **Commun. ACM**, **2012**, **Number of Citations: **127575, ([pdf](.\Papers\Imagenet_classification_with_deep_convolutional_neural_networks.pdf))([link](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)).
 - **Deep residual learning for image recognition**. K He et.al. **CoDIT**, **2016**, **Number of Citations: **211374, ([pdf](.\Papers\Deep_residual_learning_for_image_recognition.pdf))([link](http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)).
 - **Bleu: a method for automatic evaluation of machine translation**. K Papineni et.al. **ACL**, **2002**, **Number of Citations: **26918, ([pdf](.\Papers\Bleu_a_method_for_automatic_evaluation_of_machine_translation.pdf))([link](https://aclanthology.org/P02-1040.pdf)).
 - **Attention is all you need**. A Vaswani et.al. **IEEE Signal Process. Lett.**, **2017**, **Number of Citations: **115085, ([pdf](.\Papers\Attention_is_all_you_need.pdf))([link](https://proceedings.neurips.cc/paper/7181-attention-is-all)).
 - **A gentle introduction to graph nerual netwroks**. ([Link](https://distill.pub/2021/gnn-intro/))
 - BERT **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**. Jacob Devlin et.al. **arxiv**, **2018**, **Number of Citations: **None, ([pdf](.\Papers\BERT_Pre-training_of_Deep_Bidirectional_Transformers_for_Language_Understanding.pdf))([link](http://arxiv.org/abs/1810.04805v2)).
 - ViT **An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**. Alexey Dosovitskiy et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\An_Image_is_Worth_16x16_Words_Transformers_for_Image_Recognition_at_Scale.pdf))([link](http://arxiv.org/abs/2010.11929v2)).
 - MAE **Masked Autoencoders Are Scalable Vision Learners**. Kaiming He et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Masked_Autoencoders_Are_Scalable_Vision_Learners.pdf))([link](http://arxiv.org/abs/2111.06377v3)).
 - **Advancing mathematics by guiding human intuition with AI**. Davies Alex et.al. **Nature**, **2021-12-1**, **Number of Citations: **169, ([pdf](.\Papers\Advancing_mathematics_by_guiding_human_intuition_with_AI.pdf))([link](http://dx.doi.org/10.1038/s41586-021-04086-x)).
 - GPT **Improving language understanding by generative pre-training**. A Radford et.al. **NA**, **2018**, **Number of Citations: **9162, ([pdf](.\Papers\Improving_language_understanding_by_generative_pre-training.pdf))([link](https://www.mikecaptain.com/resources/pdf/GPT-1.pdf)).
 - GPT2 **Language models are unsupervised multitask learners**. A Radford et.al. **OpenAI**, **2019**, **Number of Citations: **9784, ([pdf](.\Papers\Language_models_are_unsupervised_multitask_learners.pdf))([link](https://insightcivic.s3.us-east-1.amazonaws.com/language-models.pdf)).
 - GPT3 **Language models are few-shot learners**. T Brown et.al. **ICLR**, **2020**, **Number of Citations: **24996, ([pdf](.\Papers\Language_models_are_few-shot_learners.pdf))([link](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)).

## Review
 - **Natural language processing in medicine: A review**. Locke Saskia et.al. **Trends in Anaesthesia and Critical Care**, **2021-6**, **Number of Citations: **85, ([pdf](.\Papers\Natural_language_processing_in_medicine_A_review.pdf))([link](http://dx.doi.org/10.1016/j.tacc.2021.02.007)).
 - **A Survey of Text Representation and Embedding Techniques in NLP**. Patil Rajvardhan et.al. **IEEE Access**, **2023**, **Number of Citations: **12, ([pdf](.\Papers\A_Survey_of_Text_Representation_and_Embedding_Techniques_in_NLP.pdf))([link](http://dx.doi.org/10.1109/access.2023.3266377)).
 - **Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**. Pengfei Liu et.al. **arxiv**, **2021**, **Number of Citations: **3169, ([pdf](.\Papers\Pre-train,_Prompt,_and_Predict_A_Systematic_Survey_of_Prompting_Methods_in_Natural_Language_Processing.pdf))([link](http://arxiv.org/abs/2107.13586v1)).
 - **In-context Learning with Retrieved Demonstrations for Language Models: A Survey**. Man Luo et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\In-context_Learning_with_Retrieved_Demonstrations_for_Language_Models_A_Survey.pdf))([link](http://arxiv.org/abs/2401.11624v5)).
 - **Transformers in Healthcare: A Survey**. Subhash Nerella et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Transformers_in_Healthcare_A_Survey.pdf))([link](http://arxiv.org/abs/2307.00067v1)).
 - **A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models**. Yujuan Ding et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\A_Survey_on_RAG_Meets_LLMs_Towards_Retrieval-Augmented_Large_Language_Models.pdf))([link](http://arxiv.org/abs/2405.06211v1)).
 - **Deep learning joint models for extracting entities and relations in biomedical: a survey and comparison**. Y Su et.al. **Briefings Bioinform.**, **2022**, **Number of Citations: **4, ([pdf](.\Papers\Deep_learning_joint_models_for_extracting_entities_and_relations_in_biomedical_a_survey_and_comparison.pdf))([link](https://academic.oup.com/bib/article-abstract/23/6/bbac342/6686739)).
 - **A survey of the recent trends in deep learning for literature based discovery in the biomedical domain**. Cesario Eugenio et.al. **Neurocomputing**, **2024-2**, **Number of Citations: **4, ([pdf](./Papers//A_survey_of_the_recent_trends_in_deep_learning_for_literature_based_discovery_in_the_biomedical_domain.pdf))([link](http://dx.doi.org/10.1016/j.neucom.2023.127079)).
 - **Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey**. Bonan Min et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Recent_Advances_in_Natural_Language_Processing_via_Large_Pre-Trained_Language_Models_A_Survey.pdf))([link](http://arxiv.org/abs/2111.01243v1)).
 - **Deep learning for temporal data representation in electronic health records: A systematic review of challenges and methodologies**. Xie Feng et.al. **Journal of Biomedical Informatics**, **2022-2**, **Number of Citations: **43, ([pdf](./Papers/Deep_learning_for_temporal_data_representation_in_electronic_health_records_A_systematic_review_of_challenges_and_methodologies.pdf))([link](http://dx.doi.org/10.1016/j.jbi.2021.103980)).
 - **Large Language Models in Healthcare: A Review**. Zou Shun et.al. **No journal**, **2023-10-27**, **Number of Citations: **0, ([pdf](./Papers/Large_Language_Models_in_Healthcare_A_Review.pdf))([link](http://dx.doi.org/10.1109/iscsic60498.2023.00038)).


## Models
 - **PMC-LLaMA: Towards Building Open-source Language Models for Medicine**. Chaoyi Wu et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\PMC-LLaMA_Towards_Building_Open-source_Language_Models_for_Medicine.pdf))([link](http://arxiv.org/abs/2304.14454v3)).
 - **ADELIE: Aligning Large Language Models on Information Extraction**. Yunjia Qi et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.pdf))([link](http://arxiv.org/abs/2405.05008v1)).
 - **IEPile: Unearthing Large-Scale Schema-Based Information Extraction
  Corpus**. Honghao Gui et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\IEPile_Unearthing_Large-Scale_Schema-Based_Information_Extraction_Corpus.pdf))([link](http://arxiv.org/abs/2402.14710v3)).
 - **AlpaCare:Instruction-tuned Large Language Models for Medical Application**. Xinlu Zhang et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\AlpaCareInstruction-tuned_Large_Language_Models_for_Medical_Application.pdf))([link](http://arxiv.org/abs/2310.14558v2)). 
    - Propose creating a diverse, machine-generated medical IFT dataset, MedInstruct-52k, using GPT-4 and ChatGPT with a high-quality expert-curated seed set.
    - LLaMA-series models
 - **MEDITRON-70B: Scaling Medical Pretraining for Large Language Models**. Zeming Chen et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\MEDITRON-70B_Scaling_Medical_Pretraining_for_Large_Language_Models.pdf))([link](http://arxiv.org/abs/2311.16079v1)). 
     - Based on Llama2 

## Datasets
 - **Does bert learn as humans perceive? understanding linguistic styles through lexica**. SA Hayati et.al. **EMNLP (1)**, **2021**, **Number of Citations: **24, ([pdf](.\Papers\Does_bert_learn_as_humans_perceive_understanding_linguistic_styles_through_lexica.pdf))([link](https://arxiv.org/abs/2109.02738)).
     - HUMMINGBIRD dataset
 - **BioRED: a rich biomedical relation extraction dataset**. Luo Ling et.al. **No journal**, **2022-7-19**, **Number of Citations: **30, ([pdf](.\Papers\BioRED_a_rich_biomedical_relation_extraction_dataset.pdf))([link](http://dx.doi.org/10.1093/bib/bbac282)).
 - **BioInfer: a corpus for information extraction in the biomedical domain**. Pyysalo Sampo et.al. **BMC Bioinformatics**, **2007-2-9**, **Number of Citations: **229, ([pdf](.\Papers\BioInfer_a_corpus_for_information_extraction_in_the_biomedical_domain.pdf))([link](http://dx.doi.org/10.1186/1471-2105-8-50)).
 - **ODD: A Benchmark Dataset for the Natural Language Processing based Opioid Related Aberrant Behavior Detection**. Sunjae Kwon et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\ODD_A_Benchmark_Dataset_for_the_Natural_Language_Processing_based_Opioid_Related_Aberrant_Behavior_Detection.pdf))([link](http://arxiv.org/abs/2307.02591v4)).
 - **PHEE: A Dataset for Pharmacovigilance Event Extraction from Text**. Zhaoyue Sun et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\PHEE_A_Dataset_for_Pharmacovigilance_Event_Extraction_from_Text.pdf))([link](http://arxiv.org/abs/2210.12560v1)).


## Evaluation
 - **Gemini Goes to Med School: Exploring the Capabilities of Multimodal Large Language Models on Medical Challenge Problems & Hallucinations**. Ankit Pal et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\Gemini_Goes_to_Med_School_Exploring_the_Capabilities_of_Multimodal_Large_Language_Models_on_Medical_Challenge_Problems_&_Hallucinations.pdf))([link](http://arxiv.org/abs/2402.07023v1)). 


## RAG
 - **Retrieval-augmented generation for knowledge-intensive nlp tasks**. P Lewis et.al. **NeurIPS**, **2020**, **Number of Citations: **1980, ([pdf](.\Papers\Retrieval-augmented_generation_for_knowledge-intensive_nlp_tasks.pdf))([link](https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html)).
 - **Benchmarking large language models in retrieval-augmented generation**. J Chen et.al. **AAAI**, **2024**, **Number of Citations: **42, ([pdf](.\Papers\Benchmarking_large_language_models_in_retrieval-augmented_generation.pdf))([link](https://ojs.aaai.org/index.php/AAAI/article/view/29728)).
 - **BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**. Ran Xu et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\BMRetriever_Tuning_Large_Language_Models_as_Better_Biomedical_Text_Retrievers.pdf))([link](http://arxiv.org/abs/2404.18443v1)). 
   - [https://huggingface.co/BMRetriever](https://huggingface.co/BMRetriever)
 - **REALM: Retrieval-Augmented Language Model Pre-Training**. Kelvin Guu et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\REALM_Retrieval-Augmented_Language_Model_Pre-Training.pdf))([link](http://arxiv.org/abs/2002.08909v1)).
 - **STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases**. Shirley Wu et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\STaRK_Benchmarking_LLM_Retrieval_on_Textual_and_Relational_Knowledge_Bases.pdf))([link](http://arxiv.org/abs/2404.13207v1)).
 - **UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation**. Daixuan Cheng et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\UPRISE_Universal_Prompt_Retrieval_for_Improving_Zero-Shot_Evaluation.pdf))([link](http://arxiv.org/abs/2303.08518v4)).
 - **BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine**. Mingchen Li et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.pdf))([link](http://arxiv.org/abs/2405.00465v3)).
### Retrievers
 - **Unsupervised Dense Information Retrieval with Contrastive Learning**. Gautier Izacard et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning.pdf))([link](http://arxiv.org/abs/2112.09118v4)).
   - Contriever [https://huggingface.co/facebook/contriever](https://huggingface.co/facebook/contriever)
 - **How to Train Your DRAGON: Diverse Augmentation Towards Generalizable
  Dense Retrieval**. Sheng-Chieh Lin et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\How_to_Train_Your_DRAGON_Diverse_Augmentation_Towards_Generalizable_Dense_Retrieval.pdf))([link](http://arxiv.org/abs/2302.07452v1)).
   - Dragon [https://huggingface.co/facebook/dragon-plus-context-encoder](https://huggingface.co/facebook/dragon-plus-context-encoder)
 - **SciRepEval: A Multi-Format Benchmark for Scientific Document
  Representations**. Amanpreet Singh et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\SciRepEval_A_Multi-Format_Benchmark_for_Scientific_Document_Representations.pdf))([link](http://arxiv.org/abs/2211.13308v4)).
   -  SPECTER2.0 [https://huggingface.co/allenai/specter2_base](https://huggingface.co/allenai/specter2_base)
 - **Pre-training Multi-task Contrastive Learning Models for Scientific
  Literature Understanding**. Yu Zhang et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Pre-training_Multi-task_Contrastive_Learning_Models_for_Scientific_Literature_Understanding.pdf))([link](http://arxiv.org/abs/2305.14232v2)).
   - SciMult []()
 - **COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with
  Contrastive and Distributionally Robust Learning**. Yue Yu et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\COCO-DR_Combating_Distribution_Shifts_in_Zero-Shot_Dense_Retrieval_with_Contrastive_and_Distributionally_Robust_Learning.pdf))([link](http://arxiv.org/abs/2210.15212v2)).
   - COCO-DR [https://huggingface.co/OpenMatch/cocodr-base-msmarco](https://huggingface.co/OpenMatch/cocodr-base-msmarco)
 - **SGPT: GPT Sentence Embeddings for Semantic Search**. Niklas Muennighoff et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\SGPT_GPT_Sentence_Embeddings_for_Semantic_Search.pdf))([link](http://arxiv.org/abs/2202.08904v5)).
   - SGPT-125M [https://github.com/Muennighoff/sgpt?tab=readme-ov-file#use-sgpt-with-huggingface](https://github.com/Muennighoff/sgpt?tab=readme-ov-file#use-sgpt-with-huggingface)
 - **MedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search logs for zero-shot biomedical information retrieval**. Jin Qiao et.al. **No journal**, **2023-11-1**, **Number of Citations: **10, ([pdf](.\Papers\MedCPT_Contrastive_Pre-trained_Transformers_with_large-scale_PubMed_search_logs_for_zero-shot_biomedical_information_retrieval.pdf))([link](http://dx.doi.org/10.1093/bioinformatics/btad651)).
   - [https://huggingface.co/ncbi/MedCPT-Query-Encoder](https://huggingface.co/ncbi/MedCPT-Query-Encoder)
 - **Large Dual Encoders Are Generalizable Retrievers**. Jianmo Ni et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Large_Dual_Encoders_Are_Generalizable_Retrievers.pdf))([link](http://arxiv.org/abs/2112.07899v1)). 
   - GTR-L [https://huggingface.co/sentence-transformers/gtr-t5-large](https://huggingface.co/sentence-transformers/gtr-t5-large)
 - **One Embedder, Any Task: Instruction-Finetuned Text Embeddings**. Hongjin Su et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\One_Embedder,_Any_Task_Instruction-Finetuned_Text_Embeddings.pdf))([link](http://arxiv.org/abs/2212.09741v3)).
   - InstructOR-L [https://huggingface.co/hkunlp/instructor-large](https://huggingface.co/hkunlp/instructor-large)
 - **Text Embeddings by Weakly-Supervised Contrastive Pre-training**. Liang Wang et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\Text_Embeddings_by_Weakly-Supervised_Contrastive_Pre-training.pdf))([link](http://arxiv.org/abs/2212.03533v2)).
   - E5-Large-v2 [https://huggingface.co/intfloat/e5-large-v2](https://huggingface.co/intfloat/e5-large-v2)
 - **C-Pack: Packaged Resources To Advance General Chinese Embedding**. Shitao Xiao et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\C-Pack_Packaged_Resources_To_Advance_General_Chinese_Embedding.pdf))([link](http://arxiv.org/abs/2309.07597v4)).
   - BGE-Large [https://huggingface.co/BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)
 - **BMRetriever: Tuning Large Language Models as Better Biomedical Text
  Retrievers**. Ran Xu et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\BMRetriever_Tuning_Large_Language_Models_as_Better_Biomedical_Text_Retrievers.pdf))([link](http://arxiv.org/abs/2404.18443v1)). 
   - BMRETRIEVER-410M [https://huggingface.co/BMRetriever/BMRetriever-410M](https://huggingface.co/BMRetriever/BMRetriever-410M)

## Dietary supplement
 - **Deep learning approaches for extracting adverse events and indications of dietary supplements from clinical text**. Fan Yadan et.al. **No journal**, **2020-11-5**, **Number of Citations: **11, ([pdf](.\Papers\Deep_learning_approaches_for_extracting_adverse_events_and_indications_of_dietary_supplements_from_clinical_text.pdf))([link](http://dx.doi.org/10.1093/jamia/ocaa218)).
 - **Identification of Dietary Supplement Use from Electronic Health Records Using Transformer-based Language Models**. Zhou Sicheng et.al. **No journal**, **2021-8**, **Number of Citations: **1, ([pdf](./Papers//Identification_of_Dietary_Supplement_Use_from_Electronic_Health_Records_Using_Transformer-based_Language_Models.pdf))([link](http://dx.doi.org/10.1109/ichi52183.2021.00096)).

## Bio-AI
 - **Identifying Cardiomegaly in ChestX-ray8 Using Transfer Learning.**. Sicheng Zhou et.al. **MedInfo**, **2019**, **Number of Citations: **36, ([pdf](./Papers//Identifying_Cardiomegaly_in_ChestX-ray8_Using_Transfer_Learning.pdf.pdf))([link](https://doi.org/10.3233/SHTI190268)).
 - **Toward safer health care: a review strategy of FDA medical device adverse event database to identify and categorize health information technology related events**. Kang Hong et.al. **No journal**, **2018-10-12**, **Number of Citations: **6, ([pdf](.\Papers\Toward_safer_health_care_a_review_strategy_of_FDA_medical_device_adverse_event_database_to_identify_and_categorize_health_information_technology_related_events.pdf))([link](http://dx.doi.org/10.1093/jamiaopen/ooy042)).
 - **Analysis of Twitter to Identify Topics Related to Eating Disorder Symptoms**. Zhou Sicheng et.al. **No journal**, **2019-6**, **Number of Citations: **10, ([pdf](.\Papers\Analysis_of_Twitter_to_Identify_Topics_Related_to_Eating_Disorder_Symptoms.pdf))([link](http://dx.doi.org/10.1109/ichi.2019.8904863)).
 - **CancerBERT: a cancer domain-specific language model for extracting breast cancer phenotypes from electronic health records**. Zhou Sicheng et.al. **No journal**, **2022-3-25**, **Number of Citations: **36, ([pdf](.\Papers\CancerBERT_a_cancer_domain-specific_language_model_for_extracting_breast_cancer_phenotypes_from_electronic_health_records.pdf))([link](http://dx.doi.org/10.1093/jamia/ocac040)).

## Fast inference
 - **BERT Loses Patience: Fast and Robust Inference with Early Exit**. Wangchunshu Zhou et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\BERT_Loses_Patience_Fast_and_Robust_Inference_with_Early_Exit.pdf))([link](http://arxiv.org/abs/2006.04152v3)).
    - Code: [https://github.com/JetRunner/PABEE](https://github.com/JetRunner/PABEE)
 - **F-PABEE: Flexible-Patience-Based Early Exiting For Single-Label and Multi-Label Text Classification Tasks**. Gao Xiangxiang et.al. **No journal**, **2023-6-4**, **Number of Citations: **2, ([pdf](./Papers/F-PABEE_Flexible-Patience-Based_Early_Exiting_For_Single-Label_and_Multi-Label_Text_Classification_Tasks.pdf))([link](http://dx.doi.org/10.1109/icassp49357.2023.10095864)).
 - **Adaptive Inference through Early-Exit Networks**. Laskaridis Stefanos et.al. **No journal**, **2021-6-24**, **Number of Citations: **36, ([pdf](.\Papers\Adaptive_Inference_through_Early-Exit_Networks.pdf))([link](http://dx.doi.org/10.1145/3469116.3470012)).
 - **PCEE-BERT: accelerating BERT inference via patient and confident early exiting**. Z Zhang et.al. **NAACL-HLT (Findings)**, **2022**, **Number of Citations: **23, ([pdf](.\Papers\PCEE-BERT_accelerating_BERT_inference_via_patient_and_confident_early_exiting.pdf))([link](https://aclanthology.org/2022.findings-naacl.25/)).
 - **BERxiT: Early exiting for BERT with better fine-tuning and extension to regression**. J Xin et.al. **EACL**, **2021**, **Number of Citations: **98, ([pdf](.\Papers\BERxiT_Early_exiting_for_BERT_with_better_fine-tuning_and_extension_to_regression.pdf))([link](https://aclanthology.org/2021.eacl-main.8/)).
 - 

## 2D Representation Info Extraction
 - **OneRel: Joint Entity and Relation Extraction with One Module in One Step**. Shang Yu-Ming et.al. **AAAI**, **2022-6-28**, **Number of Citations: **46, ([pdf](.\Papers\OneRel_Joint_Entity_and_Relation_Extraction_with_One_Module_in_One_Step.pdf))([link](http://dx.doi.org/10.1609/aaai.v36i10.21379)).
 - **A Bi-consolidating Model for Joint Relational Triple Extraction**. Xiaocheng Luo et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\A_Bi-consolidating_Model_for_Joint_Relational_Triple_Extraction.pdf))([link](http://arxiv.org/abs/2404.03881v2)).
 - **A Two Dimensional Feature Engineering Method for Relation Extraction**. Hao Wang et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\A_Two_Dimensional_Feature_Engineering_Method_for_Relation_Extraction.pdf))([link](http://arxiv.org/abs/2404.04959v1)).


## Uncategorized
 - **JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability**. Junda Wang et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\JMLR_Joint_Medical_LLM_and_Retrieval_Training_for_Enhancing_Reasoning_and_Professional_Question_Answering_Capability.pdf))([link](http://arxiv.org/abs/2402.17887v3)). 
 - **Almanac: Retrieval-Augmented Language Models for Clinical Medicine**. Cyril Zakka et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Almanac_Retrieval-Augmented_Language_Models_for_Clinical_Medicine.pdf))([link](http://arxiv.org/abs/2303.01229v2)).
 - **RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**. Chao Jin et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\RAGCache_Efficient_Knowledge_Caching_for_Retrieval-Augmented_Generation.pdf))([link](http://arxiv.org/abs/2404.12457v2)). 
 - **Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference**. Tuan Lai et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Joint_Biomedical_Entity_and_Relation_Extraction_with_Knowledge-Enhanced_Collective_Inference.pdf))([link](http://arxiv.org/abs/2105.13456v2)).
 - **In-context Learning with Retrieved Demonstrations for Language Models: A Survey**. Man Luo et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\In-context_Learning_with_Retrieved_Demonstrations_for_Language_Models_A_Survey.pdf))([link](http://arxiv.org/abs/2401.11624v5)).
 - **Document-level biomedical relation extraction based on multi-dimensional fusion information and multi-granularity logical reasoning**. L Li et.al. **COLING**, **2022**, **Number of Citations: **7, ([pdf](.\Papers\Document-level_biomedical_relation_extraction_based_on_multi-dimensional_fusion_information_and_multi-granularity_logical_reasoning.pdf))([link](https://aclanthology.org/2022.coling-1.183/)).
 - **Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models**. Margaret Li et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\Branch-Train-Merge_Embarrassingly_Parallel_Training_of_Expert_Language_Models.pdf))([link](http://arxiv.org/abs/2208.03306v1)).
 - **CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets**. Lifan Yuan et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\CRAFT_Customizing_LLMs_by_Creating_and_Retrieving_from_Specialized_Toolsets.pdf))([link](http://arxiv.org/abs/2309.17428v2)).
 - **TrustLLM: Trustworthiness in Large Language Models**. Lichao Sun et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\TrustLLM_Trustworthiness_in_Large_Language_Models.pdf))([link](http://arxiv.org/abs/2401.05561v4)).
 - **GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction**. Oscar Sainz et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\GoLLIE_Annotation_Guidelines_improve_Zero-Shot_Information-Extraction.pdf))([link](http://arxiv.org/abs/2310.03668v5)).
 - **Multi-task learning for natural language processing in the 2020s: Where are we going?**. Worsham Joseph et.al. **Pattern Recognition Letters**, **2020-8**, **Number of Citations: **43, ([pdf](.\Papers\Multi-task_learning_for_natural_language_processing_in_the_2020s_Where_are_we_going.pdf))([link](http://dx.doi.org/10.1016/j.patrec.2020.05.031)).


## <a id="Instruction_Tuning">Instruction Tuning</a>
 - **Instruction Tuning for Large Language Models: A Survey**. Shengyu Zhang et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\Instruction_Tuning_for_Large_Language_Models_A_Survey.pdf))([link](http://arxiv.org/abs/2308.10792v5)).



## <a id="MTL">Multi-task Learning</a>
### Review
 - **Multi-task learning in natural language processing: An overview**. S Chen et.al. **CoRR**, **2021**, **Number of Citations: **60, ([pdf](./Papers/Multi-task_learning_in_natural_language_processing_An_overview.pdf))([link](https://dl.acm.org/doi/abs/10.1145/3663363)).
   - MTL is especially meaningful for low-resource tasks and languages whose labeled dataset is sometimes too small to sufficiently train a model
   - **Parallel architecture**: shares the bulk of the model among multiple tasks while each task has its own task-specific output layer.
   ![MTL_Parallel_Architectures](./Figures/MTL-Parallel_Architectures.png "Parallel Architectures")
   - **Hierarchical architecture**: hierarchically combine features from different tasks, take the output of one task as the input of another task, or explicitly model the interaction between tasks.
   ![MTL_Hierarchical_architectures](./Figures/MTL-hierarchical_architectures.png "Hierarchical_architectures")
   - **Modular architecture**: decomposes the whole model into shared components and task-specific components that learn task-invariant and task-specific features, respectively
   - **Generative adversarial architecture**
 - **Multi-Task Deep Neural Networks for Natural Language Understanding**. Xiaodong Liu et.al. **arxiv**, **2019**, **Number of Citations: **None, ([pdf](.\Papers\Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding.pdf))([link](http://arxiv.org/abs/1901.11504v2)).
 - **Multi-task learning to improve natural language understanding**. Stefan Constantin et.al. **arxiv**, **2018**, **Number of Citations: **None, ([pdf](.\Papers\Multi-task_learning_to_improve_natural_language_understanding.pdf))([link](http://arxiv.org/abs/1812.06876v2)).
 - **A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods**. Zhihan Zhang et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\A_Survey_of_Multi-task_Learning_in_Natural_Language_Processing_Regarding_Task_Relatedness_and_Training_Methods.pdf))([link](http://arxiv.org/abs/2204.03508v2)).
 - **An Overview of Multi-Task Learning in Deep Neural Networks**. Sebastian Ruder et.al. **arxiv**, **2017**, **Number of Citations: **None, ([pdf](.\Papers\An_Overview_of_Multi-Task_Learning_in_Deep_Neural_Networks.pdf))([link](http://arxiv.org/abs/1706.05098v1)).
 - **Learning with Whom to Share in Multi-task Feature Learning.**. Zhuoliang Kang et.al. **ICML**, **2011**, **Number of Citations: **None, ([pdf](./Papers/Learning_with_Whom_to_Share_in_Multi-task_Feature_Learning.pdf))([link](https://icml.cc/2011/papers/344_icmlpaper.pdf)).
 - **Let the Model Decide its Curriculum for Multitask Learning**. Neeraj Varshney et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\Let_the_Model_Decide_its_Curriculum_for_Multitask_Learning.pdf))([link](http://arxiv.org/abs/2205.09898v2)).
 - **Multi-Task Learning with Deep Neural Networks: A Survey**. Michael Crawshaw et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\Multi-Task_Learning_with_Deep_Neural_Networks_A_Survey.pdf))([link](http://arxiv.org/abs/2009.09796v1)).
   - design of multi-task neural network architectures
   - MTL optimization methods into six distinct groups: loss weighting, regularization, gradient modulation, task scheduling, multi-objective optimization, and knowledge distillation.
   - The goal of TRL is to learn an explicit representation of tasks or relationships between tasks, such as clustering tasks into groups by similarity, and leveraging the learned task relationships to improve learning on the tasks at hand.
 - **A brief review on multi-task learning**. KH Thung et.al. **Multim. Tools Appl.**, **2018**, **Number of Citations: **225, ([pdf](./Papers/A_brief_review_on_multi-task_learning.pdf))([link](https://link.springer.com/article/10.1007/s11042-018-6463-x)).

### Methodology
 - **An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining**. Yifan Peng et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\An_Empirical_Study_of_Multi-Task_Learning_on_BERT_for_Biomedical_Text_Mining.pdf))([link](http://arxiv.org/abs/2005.02799v1)).
   - Multi-task model: BERT, Shared Layers and Task specific layers
   - Datasets: Biomedical BLUE benchmark
 - **Identifying beneficial task relations for multi-task learning in deep neural networks**. Joachim Bingel et.al. **arxiv**, **2017**, **Number of Citations: **None, ([pdf](.\Papers\Identifying_beneficial_task_relations_for_multi-task_learning_in_deep_neural_networks.pdf))([link](http://arxiv.org/abs/1702.08303v1)).
   - Model: bi-directional LSTM
   - 10 tasks
   - showing improvements in 40 outof 90 cases
   - fit a logarithmic function to the loss curve values
   - there was little evidence that dataset balance is a reliable predictor
 - **Which tasks should be learned together in multi-task learning?**. T Standley et.al. **ICML**, **2020**, **Number of Citations: **517, ([pdf](.\Papers\Which_tasks_should_be_learned_together_in_multi-task_learning.pdf))([link](https://proceedings.mlr.press/v119/standley20a.html)).
   - Computer Vision
   - Better accuarcy and less inference time
   - Pairwise multi-task relationships
 - **Intermediate-Task Transfer Learning with Pretrained Models for Natural Language Understanding: When and Why Does It Work?**. Yada Pruksachatkun et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\Intermediate-Task_Transfer_Learning_with_Pretrained_Models_for_Natural_Language_Understanding_When_and_Why_Does_It_Work.pdf))([link](http://arxiv.org/abs/2005.00628v2)).
   - RoBERTa model
   - 110 intermediate–target task combinations and 25 probing tasks
   - We observe that intermediate tasks requiring high-level inference and reasoning abilities tend to work best.
   - target task performance is strongly correlated with higher-level abilities such as coreference resolution
 - **A Hierarchical Multi-Task Approach for Learning Embeddings from Semantic Tasks**. Sanh Victor et.al. **AAAI**, **2019-7-17**, **Number of Citations: **71, ([pdf](.\Papers\A_Hierarchical_Multi-Task_Approach_for_Learning_Embeddings_from_Semantic_Tasks.pdf))([link](http://dx.doi.org/10.1609/aaai.v33i01.33016949)).
   - The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model.
 - **Exploring and Predicting Transferability across NLP Tasks**. Tu Vu et.al. **arxiv**, **2020**, **Number of Citations: **None, ([pdf](.\Papers\Exploring_and_Predicting_Transferability_across_NLP_Tasks.pdf))([link](http://arxiv.org/abs/2005.00770v2)).
   - Fisher information matrix of the feature extractor to calculate relation, but is it good?
 - **AutoSeM: Automatic Task Selection and Mixing in Multi-Task Learning**. Han Guo et.al. **arxiv**, **2019**, **Number of Citations: **None, ([pdf](.\Papers\AutoSeM_Automatic_Task_Selection_and_Mixing_in_Multi-Task_Learning.pdf))([link](http://arxiv.org/abs/1904.04153v1)).
   - multi-armed bandit controller used for task selection, Gaussian Process controller used for automatic mixing ratio (MR) learning
 - **Comic MTL: optimized multi-task learning for comic book image analysis**. Nguyen Nhu-Van et.al. **IJDAR**, **2019-7-17**, **Number of Citations: **19, ([pdf](.\Papers\Comic_MTL_optimized_multi-task_learning_for_comic_book_image_analysis.pdf))([link](http://dx.doi.org/10.1007/s10032-019-00330-3)).
 - **Efficiently Identifying Task Groupings for Multi-Task Learning.**. Chris Fifty et.al. **NeurIPS**, **2021**, **Number of Citations: **None, ([pdf](./Papers/Efficiently_Identifying_Task_Groupings_for_Multi-Task_Learning.pdf))([link](https://proceedings.neurips.cc/paper/2021/hash/e77910ebb93b511588557806310f78f1-Abstract.html)).
   - We propose to measure inter-task affinity by training all tasks together in a single multi-task network and quantifying the effect to which one task’s gradient update would affect another task’s loss.
   - it computes task groupings from only a single training run.
 - **Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons**. Yongqi Leng et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\Towards_Understanding_Multi-Task_Learning_(Generalization)_of_LLMs_via_Detecting_and_Exploring_Task-Specific_Neurons.pdf))([link](http://arxiv.org/abs/2407.06488v1)).
   - the detected neurons are highly correlated with the given task, which we term as task-specific neurons.
   -  we propose a neuron-level continuous fine-tuning method that only fine-tunes the current task-specific neurons during continuous learning
 - **A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations**. Zhao Tianyang et.al. **AAAI**, **2021-5-18**, **Number of Citations: **6, ([pdf](.\Papers\A_Unified_Multi-Task_Learning_Framework_for_Joint_Extraction_of_Entities_and_Relations.pdf))([link](http://dx.doi.org/10.1609/aaai.v35i16.17707)). 

### Models
 - **MT-clinical BERT: scaling clinical information extraction with multitask learning**. Mulyar Andriy et.al. **No journal**, **2021-8-1**, **Number of Citations: **19, ([pdf](.\Papers\MT-clinical_BERT_scaling_clinical_information_extraction_with_multitask_learning.pdf))([link](http://dx.doi.org/10.1093/jamia/ocab126)).
   - slight but consistent performance degradation in MT Clinical BERT relative to sequential fine-tuning
   - These results intuitively suggest that learning a general clinical text representation capable of supporting multiple tasks has the downside of losing the ability to exploit dataset or clinical note-specific properties
 whencomparedto asingle, task-specific model.
 - **DeepStruct: Pretraining of Language Models for Structure Prediction**. Chenguang Wang et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\DeepStruct_Pretraining_of_Language_Models_for_Structure_Prediction.pdf))([link](http://arxiv.org/abs/2205.10475v2)).
 - **InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction**. Xiao Wang et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\InstructUIE_Multi-task_Instruction_Tuning_for_Unified_Information_Extraction.pdf))([link](http://arxiv.org/abs/2304.08085v1)).
 - **Code4Struct: Code Generation for Few-Shot Event Structure Prediction**. Xingyao Wang et.al. **arxiv**, **2022**, **Number of Citations: **None, ([pdf](.\Papers\Code4Struct_Code_Generation_for_Few-Shot_Event_Structure_Prediction.pdf))([link](http://arxiv.org/abs/2210.12810v2)).
 - **GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction**. Oscar Sainz et.al. **arxiv**, **2023**, **Number of Citations: **None, ([pdf](.\Papers\GoLLIE_Annotation_Guidelines_improve_Zero-Shot_Information-Extraction.pdf))([link](http://arxiv.org/abs/2310.03668v5)).
 - **ADELIE: Aligning Large Language Models on Information Extraction**. Yunjia Qi et.al. **arxiv**, **2024**, **Number of Citations: **None, ([pdf](.\Papers\ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.pdf))([link](http://arxiv.org/abs/2405.05008v1)).
 - {{}}
 

 - **Unified Pre-training for Program Understanding and Generation**. Wasi Uddin Ahmad et.al. **arxiv**, **2021**, **Number of Citations: **None, ([pdf](.\Papers\Unified_Pre-training_for_Program_Understanding_and_Generation.pdf))([link](http://arxiv.org/abs/2103.06333v2)).

 - **Multi-task learning for few-shot biomedical relation extraction**. V Moscato et.al. **Artif. Intell. Rev.**, **2023**, **Number of Citations: **10, ([pdf](./Papers/Multi-task_learning_for_few-shot_biomedical_relation_extraction.pdf))([link](https://link.springer.com/article/10.1007/s10462-023-10484-6)).
 - **Enhancing Relation Extraction via Adversarial Multi-task Learning**. H Qin et.al. **LREC**, **2022**, **Number of Citations: **3, ([pdf](.\Papers\Enhancing_Relation_Extraction_via_Adversarial_Multi-task_Learning.pdf))([link](https://aclanthology.org/2022.lrec-1.666/)).
 - **Enhancing relation extraction using multi-task learning with SDP evidence**. H Wang et.al. **Inf. Sci.**, **2024**, **Number of Citations: **0, ([pdf](./Papers/Enhancing_relation_extraction_using_multi-task_learning_with_SDP_evidence.pdf))([link](https://www.sciencedirect.com/science/article/pii/S0020025524005231)).
 - **Multi-task and multi-view training for end-to-end relation extraction**. Zhang Junchi et.al. **Neurocomputing**, **2019-10**, **Number of Citations: **12, ([pdf](.\Papers\Multi-task_and_multi-view_training_for_end-to-end_relation_extraction.pdf))([link](http://dx.doi.org/10.1016/j.neucom.2019.06.087)).
 - **A neural network multi-task learning approach to biomedical named entity recognition**. G Crichton et.al. **BMC Bioinform.**, **2017**, **Number of Citations: **257, ([pdf](./Papers/A_neural_network_multi-task_learning_approach_to_biomedical_named_entity_recognition.pdf))([link](https://link.springer.com/article/10.1186/s12859-017-1776-8)).

 - **Neural multi-task learning in drug design**. ([pdf](./Papers//your_pdf_name.pdf)).